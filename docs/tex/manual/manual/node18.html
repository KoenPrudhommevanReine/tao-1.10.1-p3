<HTML>
<HEAD>
<!-- This file was generated by tohtml from part1.tex -->
<!-- with the command
tohtml -default -numbers -mapman www.cit manual.tex -notopnames -mapref ../../manualpages/manualpages.cit -quietlatex 
-->
<TITLE>Parallel Programming</TITLE>
</HEAD>
<BODY BGCOLOR="#FFFFFF">
<HR><H2><A NAME="Node18">13.5. Parallel Programming</a></H2>
Since TAO uses the message-passing model for parallel programming and  
employs MPI for all interprocessor communication, the user is free to  
employ MPI routines as needed throughout an application code.  
However, by default the user is shielded from many of the details of  
message passing within TAO, since these are hidden within parallel  
objects, such as vectors, matrices, and solvers.  In addition, TAO  
users can interface to external tools, such as the generalized vector  
scatters/gathers and distributed arrays within PETSc, to assist in the  
management of parallel data.  
<P> 
The user must specify a communicator  
upon creation of any TAO objects (such as a vector, matrix, or solver)  
to indicate the processors over which the object is to be distributed.  
For example, some commands for matrix, vector, and solver creation  
are:  
<BR> 
<pre><tt>   info = MatCreate(MPI_Comm comm,int m,int n,int M,int N,Mat *H); 
   info = VecCreate(MPI_Comm comm,int m,int M,Vec *x); 
   info = <a href="../manualpages/solver/TaoCreate.html#TaoCreate">TaoCreate</a>(MPI_Comm comm,TaoMethod method,TAO_SOLVER *tao);  
</tt></pre> 
  
The creation routines are collective over all processors in the  
communicator; thus, all processors in the communicator <em> must</em> call  
the creation routine.  In addition, if a sequence of collective  
routines is being used, the routines <em> must</em> be called in the same  
order on each processor.  
<P> 

<P>
<HR>
</BODY>
</HTML>
