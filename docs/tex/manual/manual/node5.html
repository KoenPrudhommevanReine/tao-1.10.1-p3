<HTML>
<HEAD>
<!-- This file was generated by tohtml from part0.tex -->
<!-- with the command
tohtml -default -numbers -mapman www.cit manual.tex -notopnames -mapref ../../manualpages/manualpages.cit -quietlatex 
-->
<TITLE>Performance Results</TITLE>
</HEAD>
<BODY BGCOLOR="#FFFFFF">
<HR><H1><A NAME="Node5">5. Performance Results</a></H1>
A major concern in the TAO project is the performance and scalability  
of optimization algorithms on large problems.  In this section we  
focus on the GPCG (gradient projection, conjugate gradient) algorithm  
for the solution of bound-constrained convex quadratic programming  
problems.  Originally developed by Mor&#233; and Toraldo  
[(ref more-toraldo)], the GPCG algorithm was designed for large-scale  
problems but had only been implemented for a single processor.  GPCG  
combines the advantages of the identification properties of the  
gradient projection method with the finite termination properties of  
the conjugate gradient method.  Moreover, the performance of the  
TAO implementation on large optimization problems is noteworthy.  
<P> 
<P> 
<CENTER><P><IMG WIDTH=443 HEIGHT=278 SRC="pjb.gif"><P>
</CENTER>  
<BR> 
<b>Figure 2: </b><A NAME="Figure2">The journal bearing problem with $$ = 0.9</a><P> 
  
  
We illustrate the performance of the GPCG algorithm by   
presenting results for a journal bearing problem  
with over 2.5 million variables.  
The journal bearing problem  
is a finite element approximation to a variational problem   
over a rectangular two-dimensional grid.  A  
grid with <I>1600</I> points in each direction, for example, is formulated  
as a bound constrained quadratic problem with <I>1600<SUP>2</SUP>=2,560,000</I>  
variables.  
The triangulation of the grid results in a matrix that has the  
usual five diagonal nonzero structure that arises  
from a difference approximation to the Laplacian operator.  
The journal bearing problem contains an eccentricity parameter,  
<IMG WIDTH=41 HEIGHT=11 SRC="img1.xbm">
, that influences the number of active  
variables at the solution and the difficulty in solving it.  
Figure  shows the solution of the journal bearing problem  
for <IMG WIDTH=33 HEIGHT=7 SRC="img2.xbm">
. The steep gradient in the solution  
makes this problem a difficult benchmark.  
<P> 
The performance results in Table  are noteworthy is several  
ways.  First of all, the number of faces visited by GPCG is remarkably  
small.  Other strategies can lead to a large number of gradient  
projection iterates, but the GPCG algorithm is remarkably efficient.  
Another interesting aspect of these results is that due to the low  
memory requirements of iterative solvers, we were able to solve these  
problems with only <I>p = 8</I> processors.  Strategies that rely on  
direct solvers are likely to need significantly more storage, and thus  
more processors.  Finally, these results show that the GPCG  
implementation has excellent efficiency.  For example, the efficiency  
of GPCG with respect to <I>p = 8</I> processors ranges between <IMG WIDTH=20 HEIGHT=10 SRC="img3.xbm">
  
and <IMG WIDTH=24 HEIGHT=10 SRC="img4.xbm">
 when <IMG WIDTH=33 HEIGHT=7 SRC="img5.xbm">
.  This sustained efficiency  
is remarkable since the GPCG algorithm is solving a sequence of linear  
problems with a coefficient matrix set to the submatrix of the Hessian  
matrix with respect to the free variables for the current iterate.  
Thus, our implementation's repartitioning of submatrices effectively  
deals with the load-balancing problem that is inherent in the GPCG  
algorithm.  
<P> 
<P><A NAME="node5.html#Table1"><IMG WIDTH=331 HEIGHT=148 SRC="img6.xbm"></a><P>
An important aspect of our results that is not  
apparent from Table  is that   
for these results we were able to experiment easily   
with all the preconditioners offered by PETSc.  
In particular, we were able to compare the diagonal Jacobi  
preconditioner with block Jacobi and overlapping additive Schwarz  
preconditioners that use a zero-fill ILU solver in each block.  We  
also experimented with a parallel zero-fill incomplete Cholesky preconditioner  
provided by a PETSc interface to the BlockSolve95 [(ref bs-user-ref)]  
package of Jones and  
Plassmann.  Interestingly enough, the diagonal Jacobi preconditioner  
achieved better performance on this problem.  
<P> 
<P> 

<P>
<HR>
</BODY>
</HTML>
